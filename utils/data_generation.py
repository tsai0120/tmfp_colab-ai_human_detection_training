"""
AI æ–‡æœ¬ç”Ÿæˆç³»çµ± - ä½¿ç”¨ä¸‰ç¨®ä¸åŒçš„ Prompt æ¨¡æ¿
æ”¯æ´ OpenAI API æˆ–æœ¬åœ° LLM
"""

import os
import csv
import json
import random
from typing import List, Dict, Optional
from openai import OpenAI
import pandas as pd

# ä¸‰ç¨® Prompt æ¨¡æ¿
PROMPT_TEMPLATES = {
    "A_instruction": """è«‹ä»¥æ­£å¼ã€å­¸è¡“çš„èªæ°£ï¼Œæ’°å¯«ä¸€ç¯‡é—œæ–¼ã€Œ{topic}ã€çš„æ–‡ç« ã€‚

è¦æ±‚ï¼š
1. ç¬¬ä¸€æ®µï¼šä»‹ç´¹ä¸»é¡Œçš„èƒŒæ™¯èˆ‡é‡è¦æ€§
2. ç¬¬äºŒæ®µï¼šæ·±å…¥åˆ†æä¸»è¦è§€é»èˆ‡è«–è­‰
3. ç¬¬ä¸‰æ®µï¼šç¸½çµä¸¦æå‡ºæœªä¾†å±•æœ›

è«‹ç¢ºä¿æ–‡ç« çµæ§‹æ¸…æ™°ã€é‚è¼¯åš´è¬¹ã€ç”¨è©ç²¾æº–ã€‚""",

    "B_narrative": """å¯«ä¸€ç¯‡é—œæ–¼ã€Œ{topic}ã€çš„æ–‡ç« ï¼Œç”¨å¤§å­¸ç”Ÿå¯«ä½œæ¥­çš„é¢¨æ ¼ï¼Œå£èªåŒ–ä¸€é»ï¼Œä¸è¦å¤ªæ­£å¼ã€‚

å¯ä»¥åˆ†äº«ä½ çš„æƒ³æ³•ã€ç¶“é©—ï¼Œæˆ–è€…ä½ å°é€™å€‹ä¸»é¡Œçš„çœ‹æ³•ã€‚å°±åƒåœ¨è·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£ï¼Œä½†é‚„æ˜¯è¦æœ‰é»å…§å®¹ã€‚""",

    "C_role": """ä½ æ˜¯ä¸€ä½å……æ»¿æƒ…æ„Ÿçš„è©©äºº/ä½œå®¶ï¼Œè«‹ä»¥ã€Œ{topic}ã€ç‚ºä¸»é¡Œï¼Œå¯«ä¸€ç¯‡å¯Œæœ‰æƒ…æ„Ÿèˆ‡å€‹äººè‰²å½©çš„æ–‡ç« ã€‚

ç”¨ä½ çš„å¿ƒéˆå»æ„Ÿå—é€™å€‹ä¸»é¡Œï¼Œç”¨æ–‡å­—è¡¨é”ä½ çš„æƒ…ç·’ã€æƒ³åƒèˆ‡å‰µæ„ã€‚ä¸è¦æ‹˜æ³¥æ–¼æ ¼å¼ï¼Œè®“æ–‡å­—è‡ªç„¶æµå‹•ã€‚"""
}


class AITextGenerator:
    """AI æ–‡æœ¬ç”Ÿæˆå™¨"""
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gpt-3.5-turbo",
        base_url: Optional[str] = None
    ):
        """
        Args:
            api_key: OpenAI API keyï¼ˆå¦‚æœä½¿ç”¨ OpenAIï¼‰
            model: æ¨¡å‹åç¨±
            base_url: è‡ªè¨‚ API base URLï¼ˆç”¨æ–¼æœ¬åœ° LLMï¼‰
        """
        self.model = model
        if api_key or base_url:
            self.client = OpenAI(
                api_key=api_key or "dummy",
                base_url=base_url
            )
        else:
            self.client = None
            print("âš ï¸  æœªè¨­å®š APIï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬ç”Ÿæˆæ¨¡å¼")
    
    def generate_text(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 500
    ) -> str:
        """ç”Ÿæˆå–®ç¯‡æ–‡æœ¬"""
        if not self.client:
            # æ¨¡æ“¬ç”Ÿæˆï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
            return f"[æ¨¡æ“¬ç”Ÿæˆæ–‡æœ¬ - Prompt: {prompt[:50]}...]"
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¯«ä½œåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            return f"[ç”ŸæˆéŒ¯èª¤: {str(e)}]"
    
    def generate_batch(
        self,
        topics: List[str],
        prompt_type: str,
        num_per_topic: int = 10,
        temperature: float = 0.7,
        max_tokens: int = 500
    ) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆæ–‡æœ¬"""
        results = []
        template = PROMPT_TEMPLATES.get(prompt_type, PROMPT_TEMPLATES["A_instruction"])
        
        for topic in topics:
            print(f"ğŸ“ ç”Ÿæˆ {prompt_type} - ä¸»é¡Œ: {topic}")
            for i in range(num_per_topic):
                prompt = template.format(topic=topic)
                text = self.generate_text(prompt, temperature, max_tokens)
                
                results.append({
                    "text": text,
                    "topic": topic,
                    "prompt_type": prompt_type,
                    "label": "AI"  # AI ç”Ÿæˆçš„æ¨™ç±¤
                })
                
                if (i + 1) % 5 == 0:
                    print(f"   âœ“ å·²å®Œæˆ {i + 1}/{num_per_topic}")
        
        return results


def load_topics(file_path: str = "data/topics.txt") -> List[str]:
    """è¼‰å…¥ä¸»é¡Œåˆ—è¡¨"""
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            topics = [line.strip() for line in f if line.strip()]
        return topics
    else:
        # é è¨­ä¸»é¡Œ
        default_topics = [
            "äººå·¥æ™ºæ…§çš„æœªä¾†ç™¼å±•",
            "ç’°å¢ƒä¿è­·èˆ‡æ°¸çºŒç™¼å±•",
            "é è·å·¥ä½œçš„å„ªç¼ºé»",
            "æ•™è‚²æ”¹é©çš„å¿…è¦æ€§",
            "ç§‘æŠ€å°ç”Ÿæ´»çš„å½±éŸ¿",
            "å¥åº·é£²é£Ÿçš„é‡è¦æ€§",
            "é–±è®€ç¿’æ…£çš„åŸ¹é¤Š",
            "æ—…éŠçš„æ„ç¾©èˆ‡åƒ¹å€¼",
            "éŸ³æ¨‚å°æƒ…ç·’çš„å½±éŸ¿",
            "é‹å‹•èˆ‡èº«å¿ƒå¥åº·"
        ]
        # å»ºç«‹ topics.txt
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write("\n".join(default_topics))
        return default_topics


def generate_ai_texts(
    output_path: str = "data/generated_ai.csv",
    num_per_prompt: int = 15,
    temperature: float = 0.7,
    max_tokens: int = 500,
    api_key: Optional[str] = None,
    model: str = "gpt-3.5-turbo",
    base_url: Optional[str] = None
):
    """
    ä¸»å‡½æ•¸ï¼šç”Ÿæˆ AI æ–‡æœ¬ä¸¦å„²å­˜ç‚º CSV
    
    Args:
        output_path: è¼¸å‡º CSV è·¯å¾‘
        num_per_prompt: æ¯å€‹ prompt é¡å‹ç”Ÿæˆçš„æ–‡ç« æ•¸
        temperature: ç”Ÿæˆæº«åº¦
        max_tokens: æœ€å¤§ token æ•¸
        api_key: OpenAI API key
        model: æ¨¡å‹åç¨±
        base_url: è‡ªè¨‚ API base URL
    """
    print("ğŸš€ é–‹å§‹ç”Ÿæˆ AI æ–‡æœ¬...")
    
    # è¼‰å…¥ä¸»é¡Œ
    topics = load_topics()
    print(f"ğŸ“š è¼‰å…¥ {len(topics)} å€‹ä¸»é¡Œ")
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = AITextGenerator(api_key=api_key, model=model, base_url=base_url)
    
    # ç”Ÿæˆä¸‰ç¨® prompt é¡å‹çš„æ–‡æœ¬
    all_results = []
    for prompt_type in ["A_instruction", "B_narrative", "C_role"]:
        num_per_topic = max(1, num_per_prompt // len(topics))
        results = generator.generate_batch(
            topics=topics,
            prompt_type=prompt_type,
            num_per_topic=num_per_topic,
            temperature=temperature,
            max_tokens=max_tokens
        )
        all_results.extend(results)
        print(f"âœ… {prompt_type}: ç”Ÿæˆ {len(results)} ç¯‡")
    
    # å„²å­˜ç‚º CSV
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df = pd.DataFrame(all_results)
    df.to_csv(output_path, index=False, encoding="utf-8")
    print(f"ğŸ’¾ å·²å„²å­˜è‡³ {output_path}")
    print(f"ğŸ“Š ç¸½è¨ˆç”Ÿæˆ {len(all_results)} ç¯‡ AI æ–‡æœ¬")
    
    return df


if __name__ == "__main__":
    # å¾ç’°å¢ƒè®Šæ•¸è®€å– API keyï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
    api_key = os.getenv("OPENAI_API_KEY")
    
    # ç”Ÿæˆæ–‡æœ¬ï¼ˆå¯èª¿æ•´åƒæ•¸ï¼‰
    generate_ai_texts(
        output_path="data/generated_ai.csv",
        num_per_prompt=15,  # æ¯å€‹ prompt é¡å‹ç”Ÿæˆ 15 ç¯‡
        temperature=0.7,
        max_tokens=500,
        api_key=api_key,
        model="gpt-3.5-turbo"
    )

