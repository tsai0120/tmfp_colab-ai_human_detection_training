# ⏱️ 訓練時間說明

## 📊 正常訓練時間

### TF-IDF + SVM
- **資料量**: 70,000 筆訓練資料
- **預期時間**: **5-30 分鐘**（取決於 kernel）
  - Linear kernel: 約 2-5 分鐘
  - RBF kernel: 約 10-30 分鐘 ⚠️ **較慢但效果較好**
  - Polynomial kernel: 約 15-30 分鐘

**為什麼這麼慢？**
- SVM 需要計算所有樣本之間的相似度（RBF kernel）
- 70,000 筆資料 × 5,000 特徵 = 大量計算
- 這是**正常的**，請耐心等待

### TF-IDF + Logistic Regression
- **預期時間**: **1-5 分鐘**
- 比 SVM 快很多

### BERT / RoBERTa + LoRA
- **預期時間**: **30 分鐘 - 數小時**（取決於 GPU）
- 需要 GPU 加速
- 如果只有 CPU，可能需要數小時

### Hybrid
- **預期時間**: **10-20 分鐘**
- 需要先訓練 SVM 和 LR

## 🔍 如何判斷訓練是否正常？

### ✅ 正常跡象
1. 終端有輸出（顯示訓練進度）
2. CPU 使用率較高（表示正在計算）
3. 記憶體使用穩定
4. 沒有錯誤訊息

### ⚠️ 異常跡象
1. 完全沒有輸出超過 10 分鐘
2. 記憶體使用持續增長（可能記憶體不足）
3. 出現錯誤訊息
4. CPU 使用率為 0（可能卡住了）

## 💡 加速訓練的建議

### 1. 減少資料量
```bash
# 只使用 20,000 筆資料
python train_pipeline/train_svm.py --data AI_Human.csv
# 然後修改 train_svm.py 中的 nrows=20000
```

### 2. 使用 Linear Kernel（較快）
```bash
python train_pipeline/train_svm.py --data AI_Human.csv --kernel linear
```

### 3. 減少特徵數
```bash
python train_pipeline/train_svm.py --data AI_Human.csv --max_features 2000
```

### 4. 使用較小的 C 參數
```bash
python train_pipeline/train_svm.py --data AI_Human.csv --C 0.1
```

## 📈 進度顯示

### 終端輸出
訓練腳本會顯示：
- ✅ 載入資料進度
- ✅ 預處理進度
- ✅ TF-IDF 向量化進度
- ✅ 訓練進度（如果使用 verbose=True）
- ✅ 評估進度
- ✅ 儲存進度

### 前端顯示
在模型管理頁面（Admin）：
- 📊 即時進度條（0-100%）
- 📝 當前階段訊息
- ⏱️ 開始時間
- ✅ 完成通知

## 🚨 如果訓練卡住了

### 檢查步驟
1. **查看終端輸出**：是否有新的訊息？
2. **檢查 CPU/記憶體**：是否還在運算？
3. **等待時間**：SVM RBF 可能需要 20-30 分鐘
4. **強制停止**：按 `Ctrl+C（會丟失進度）

### 重新開始
如果確定卡住了：
```bash
# 停止當前訓練（Ctrl+C）
# 然後重新開始，可以嘗試：
python train_pipeline/train_svm.py --data AI_Human.csv --kernel linear
```

## 📝 訓練日誌

訓練完成後會顯示：
```
✅ 訓練完成！
⏱️  訓練時間: 15.32 分鐘 (919.20 秒)
✅ 驗證集準確率: 0.8523
✅ 測試集準確率: 0.8487
💾 模型已儲存至 models/tfidf_svm
```

## 🎯 建議訓練順序

1. **先訓練 LR**（最快，1-5 分鐘）
   ```bash
   python train_pipeline/train_lr.py --data AI_Human.csv
   ```

2. **再訓練 SVM**（較慢，5-30 分鐘）
   ```bash
   python train_pipeline/train_svm.py --data AI_Human.csv
   ```

3. **最後訓練 Hybrid**（需要 SVM 和 LR）
   ```bash
   python train_pipeline/train_hybrid.py --data AI_Human.csv
   ```

4. **BERT/LoRA**（如果有 GPU，可以同時進行）

## 💻 系統需求

### 最低需求
- **記憶體**: 至少 8GB RAM
- **CPU**: 多核心處理器
- **時間**: 耐心等待 5-30 分鐘

### 推薦配置
- **記憶體**: 16GB+ RAM
- **CPU**: 8 核心以上
- **GPU**: 用於 BERT/LoRA（可選）

## ❓ 常見問題

**Q: 訓練已經跑了 10 分鐘，正常嗎？**
A: 是的，SVM RBF kernel 訓練 70,000 筆資料通常需要 10-30 分鐘。

**Q: 可以中途停止嗎？**
A: 可以按 Ctrl+C，但會丟失進度，需要重新開始。

**Q: 如何知道訓練完成了？**
A: 終端會顯示「✅ 訓練完成！」和準確率資訊。

**Q: 訓練時電腦變慢正常嗎？**
A: 正常，SVM 訓練會使用大量 CPU 和記憶體。

**Q: 可以同時訓練多個模型嗎？**
A: 不建議，會導致資源競爭，建議依序訓練。

