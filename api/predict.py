"""
æŽ¨è«– API - FastAPI
æä¾›æ–‡æœ¬åµæ¸¬æœå‹™
"""

import os
import sys
from pathlib import Path
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, List
import uvicorn

# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent))
from utils.model_loader import ModelLoader

app = FastAPI(title="AI vs Human æ–‡æœ¬åµæ¸¬ API")

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰é™åˆ¶ç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨åŸŸæ¨¡åž‹è¼‰å…¥å™¨
model_loader = ModelLoader(models_dir="models")


class TextRequest(BaseModel):
    """æ–‡æœ¬è«‹æ±‚æ¨¡åž‹"""
    text: str
    selected_model: Optional[str] = None  # å¯é¸ï¼šåªä½¿ç”¨ç‰¹å®šæ¨¡åž‹


class PredictionResponse(BaseModel):
    """é æ¸¬å›žæ‡‰æ¨¡åž‹"""
    selected_model: str
    probability_ai: float
    label: str  # "AI" æˆ– "Human"
    details: Dict[str, float]  # æ‰€æœ‰æ¨¡åž‹çš„é æ¸¬çµæžœ


@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡åž‹"""
    print("ðŸš€ å•Ÿå‹• API æœå‹™...")
    print("ðŸ“¥ è¼‰å…¥æ¨¡åž‹...")
    results = model_loader.load_all_models()
    
    loaded_count = sum(1 for success in results.values() if success)
    print(f"âœ… å·²è¼‰å…¥ {loaded_count}/{len(results)} å€‹æ¨¡åž‹")
    
    for model_name, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {model_name}")


@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {
        "message": "AI vs Human æ–‡æœ¬åµæ¸¬ API",
        "version": "1.0.0",
        "endpoints": {
            "/predict": "POST - æ–‡æœ¬åµæ¸¬",
            "/health": "GET - å¥åº·æª¢æŸ¥",
            "/models": "GET - å¯ç”¨æ¨¡åž‹åˆ—è¡¨"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "models_loaded": len(model_loader.loaded_models)
    }


@app.get("/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡åž‹"""
    available_models = list(model_loader.loaded_models.keys())
    return {
        "available_models": available_models,
        "count": len(available_models)
    }


@app.post("/predict", response_model=PredictionResponse)
async def predict(request: TextRequest):
    """
    æ–‡æœ¬åµæ¸¬
    
    Args:
        request: åŒ…å«æ–‡æœ¬å’Œå¯é¸çš„æ¨¡åž‹é¸æ“‡
    
    Returns:
        é æ¸¬çµæžœï¼ŒåŒ…å« AI æ©ŸçŽ‡å’Œæ‰€æœ‰æ¨¡åž‹çš„è©³ç´°çµæžœ
    """
    if not request.text or len(request.text.strip()) == 0:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ç‚ºç©º")
    
    text = request.text.strip()
    
    # å¦‚æžœæŒ‡å®šäº†ç‰¹å®šæ¨¡åž‹
    if request.selected_model:
        model_name = request.selected_model.lower()
        
        if model_name == "svm" or model_name == "tfidf_svm":
            prob = model_loader.predict_tfidf_svm(text)
            return PredictionResponse(
                selected_model="svm",
                probability_ai=prob,
                label="AI" if prob > 0.5 else "Human",
                details={"svm": prob}
            )
        elif model_name == "lr" or model_name == "tfidf_lr":
            prob = model_loader.predict_tfidf_lr(text)
            return PredictionResponse(
                selected_model="lr",
                probability_ai=prob,
                label="AI" if prob > 0.5 else "Human",
                details={"lr": prob}
            )
        elif model_name == "bert":
            prob = model_loader.predict_bert(text)
            return PredictionResponse(
                selected_model="bert",
                probability_ai=prob,
                label="AI" if prob > 0.5 else "Human",
                details={"bert": prob}
            )
        elif model_name == "lora" or model_name == "roberta_lora":
            prob = model_loader.predict_roberta_lora(text)
            return PredictionResponse(
                selected_model="lora",
                probability_ai=prob,
                label="AI" if prob > 0.5 else "Human",
                details={"lora": prob}
            )
        elif model_name == "hybrid":
            prob = model_loader.predict_hybrid(text)
            return PredictionResponse(
                selected_model="hybrid",
                probability_ai=prob,
                label="AI" if prob > 0.5 else "Human",
                details={"hybrid": prob}
            )
        else:
            raise HTTPException(
                status_code=400,
                detail=f"æœªçŸ¥çš„æ¨¡åž‹: {model_name}ã€‚å¯ç”¨æ¨¡åž‹: svm, lr, bert, lora, hybrid"
            )
    
    # ä½¿ç”¨æ‰€æœ‰æ¨¡åž‹é æ¸¬
    try:
        all_predictions = model_loader.predict_all(text)
        
        # é¸æ“‡æœ€é«˜æ©ŸçŽ‡ä½œç‚ºæœ€çµ‚çµæžœï¼ˆæˆ–ä½¿ç”¨ hybridï¼‰
        if 'hybrid' in all_predictions and all_predictions['hybrid'] != 0.5:
            final_prob = all_predictions['hybrid']
            selected_model = "hybrid"
        else:
            # ä½¿ç”¨å¹³å‡æ©ŸçŽ‡
            valid_probs = [p for p in all_predictions.values() if p != 0.5]
            if valid_probs:
                final_prob = sum(valid_probs) / len(valid_probs)
            else:
                final_prob = 0.5
            selected_model = "ensemble"
        
        return PredictionResponse(
            selected_model=selected_model,
            probability_ai=final_prob,
            label="AI" if final_prob > 0.5 else "Human",
            details=all_predictions
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é æ¸¬å¤±æ•—: {str(e)}")


@app.post("/predict/batch")
async def predict_batch(texts: List[str]):
    """
    æ‰¹é‡é æ¸¬
    
    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
    
    Returns:
        æ‰¹é‡é æ¸¬çµæžœ
    """
    if not texts or len(texts) == 0:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬åˆ—è¡¨ä¸èƒ½ç‚ºç©º")
    
    results = []
    for text in texts:
        try:
            all_predictions = model_loader.predict_all(text)
            valid_probs = [p for p in all_predictions.values() if p != 0.5]
            final_prob = sum(valid_probs) / len(valid_probs) if valid_probs else 0.5
            
            results.append({
                "text": text[:100] + "..." if len(text) > 100 else text,
                "probability_ai": final_prob,
                "label": "AI" if final_prob > 0.5 else "Human",
                "details": all_predictions
            })
        except Exception as e:
            results.append({
                "text": text[:100] + "..." if len(text) > 100 else text,
                "error": str(e)
            })
    
    return {"results": results, "count": len(results)}


if __name__ == "__main__":
    uvicorn.run(
        "predict:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )

